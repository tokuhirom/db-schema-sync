# DB Schema Sync

> [!WARNING]
> **This project has been archived.** Please use [dbmate-deployer](https://github.com/tokuhirom/dbmate-deployer) instead, which provides similar functionality with dbmate-based migrations.

---

A tool to synchronize database schemas from S3 using psqldef.

## What is db-schema-sync?

**db-schema-sync** is a declarative database schema management tool - think "Terraform for databases". Instead of writing migration files, you define your desired schema state in a single `schema.sql` file, and the tool automatically generates and applies the necessary ALTER queries to reconcile any differences.

**Key Concepts:**

- **Declarative approach**: You declare the desired state (what tables, columns, indexes you want), not the migration steps
- **Powered by psqldef**: Automatically generates safe DDL (ALTER TABLE, CREATE INDEX, etc.) by comparing current database state with your schema file
- **S3 as source of truth**: Schema versions are stored in S3, enabling GitOps workflows and centralized schema management
- **Safe concurrent applies**: PostgreSQL advisory locks prevent multiple instances from applying schemas simultaneously
- **Production-ready**: Built-in lifecycle hooks, Prometheus metrics, error handling, and schema export capabilities

**How it differs from traditional migrations:**

| Traditional Migrations | db-schema-sync |
|------------------------|----------------|
| Write sequential migration files | Define desired state in schema.sql |
| Manually write ALTER queries | Auto-generated by psqldef |
| Migration history in application | Schema versions in S3 |
| Must replay all migrations | Direct application of target state |

## Typical Workflow

db-schema-sync enables a complete CI/CD workflow for database schema management:

```
┌─────────────────────────────────────────────────────────────────────┐
│  1. Developer modifies schema.sql in Git repository                │
└────────────────┬────────────────────────────────────────────────────┘
                 │
                 ▼
┌─────────────────────────────────────────────────────────────────────┐
│  2. GitHub Actions: PR opened                                       │
│     • Fetch current schema from S3                                 │
│     • Run: db-schema-sync plan schema.sql                          │
│     • Post DDL diff as PR comment (shows ALTER queries)            │
└────────────────┬────────────────────────────────────────────────────┘
                 │
                 ▼
┌─────────────────────────────────────────────────────────────────────┐
│  3. Review & Merge PR                                               │
│     • Team reviews DDL changes in PR comment                        │
│     • Approves and merges                                           │
└────────────────┬────────────────────────────────────────────────────┘
                 │
                 ▼
┌─────────────────────────────────────────────────────────────────────┐
│  4. GitHub Actions: Post-merge                                      │
│     • Generate version (timestamp: 20260120153045)                  │
│     • Upload schema.sql to S3: s3://bucket/schemas/v20260120153045/ │
└────────────────┬────────────────────────────────────────────────────┘
                 │
                 ▼
┌─────────────────────────────────────────────────────────────────────┐
│  5. Watch Container (running in production)                         │
│     • Polls S3 every minute                                         │
│     • Detects new version: v20260120153045                          │
│     • Acquires PostgreSQL advisory lock                             │
│     • Applies schema via psqldef                                    │
│     • Exports applied schema to S3                                  │
│     • Creates completion marker                                     │
│     • Executes on-apply-succeeded hook                              │
└────────────────┬────────────────────────────────────────────────────┘
                 │
                 ▼
┌─────────────────────────────────────────────────────────────────────┐
│  6. Notification (via lifecycle hook)                               │
│     • Slack notification: "Schema v20260120153045 applied"          │
│     • Includes DDL diff and success/failure status                  │
└─────────────────────────────────────────────────────────────────────┘
```

**Benefits of this workflow:**

- **Visibility**: Team sees exact DDL changes before merge
- **Safety**: Review process catches breaking changes early
- **Automation**: No manual schema application steps
- **Auditability**: S3 versions provide complete schema history
- **Rollback-ready**: Previous versions remain in S3 for rollback scenarios

See the [GitHub Actions Integration](#github-actions-integration) section for complete implementation examples.

## Features

- Periodically polls S3 for schema file updates (watch mode)
- Single-shot schema application (apply mode)
- Plan mode for offline schema comparison (plan mode)
- Fetch latest completed schema from S3 (fetch-completed mode)
- Export schema after apply and upload to S3
- Semantic version sorting for schema versions
- Uses psqldef for safe schema migrations
- Lifecycle hooks for startup, success, and error notifications
- Flexible configuration via environment variables or CLI flags
- S3-compatible storage support (Sakura Cloud, MinIO, etc.)
- Dockerized for easy deployment

## License

This project is licensed under the MIT License.

## Usage

### Subcommands

```
db-schema-sync watch            # Run in daemon mode, continuously polling for schema updates
db-schema-sync apply            # Apply schema once and exit
db-schema-sync plan             # Show DDL changes between S3 schema and local file (like terraform plan)
db-schema-sync fetch-completed  # Fetch latest completed schema from S3
```

### How it works

This tool monitors an S3 bucket for schema file updates. Schema files are organized in S3 with version-based directories:

**S3 Bucket Structure:**

```
s3://my-bucket/schemas/
├── 20260115120000/          # Timestamp version
│   ├── schema.sql
│   ├── completed
│   └── exported.sql
└── 20260120153045/          # Latest version
    ├── schema.sql           # ← This will be applied
    ├── completed            # ← Created after apply
    └── exported.sql         # ← Exported schema (if enabled)
```

**Path Configuration:**
- **Bucket**: `my-bucket` (set via `--s3-bucket` or `S3_BUCKET`)
- **Path prefix**: `schemas/` (set via `--path-prefix` or `PATH_PREFIX`)
- **Version**: Semantic version (`v1`, `v2.1.0`) or timestamp (`20260120153045`)
- **Schema file**: `schema.sql` (configurable via `--schema-file`)
- **Completion marker**: `completed` (configurable via `--completed-file`)

**Watch Mode Operation:**

The tool continuously polls S3 and applies new schemas when detected:

```
┌──────────────┐
│ Poll S3      │  Every --interval (default: 1m)
└──────┬───────┘
       │
       ▼
┌──────────────────────┐
│ List all versions    │  Find highest version using semver comparison
│ s3://bucket/prefix/  │
└──────┬───────────────┘
       │
       ▼
┌──────────────────────┐
│ Check if completed   │  Skip if completion marker exists
│ marker exists        │
└──────┬───────────────┘
       │ New version detected
       ▼
┌──────────────────────┐
│ Acquire advisory     │  pg_try_advisory_lock() - prevents concurrent applies
│ lock on PostgreSQL   │  If locked by another instance, skip and log
└──────┬───────────────┘
       │
       ▼
┌──────────────────────┐
│ Download schema.sql  │  From s3://bucket/prefix/VERSION/schema.sql
└──────┬───────────────┘
       │
       ▼
┌──────────────────────┐
│ Execute              │  Run hook script if configured
│ on-before-apply hook │  (receives DDL diff via DB_SCHEMA_SYNC_DRY_RUN)
└──────┬───────────────┘
       │
       ▼
┌──────────────────────┐
│ Apply via psqldef    │  psqldef generates and executes ALTER queries
│                      │  Compares desired state vs current database
└──────┬───────────────┘
       │
       ▼
┌──────────────────────┐
│ Export schema        │  If --export-after-apply is set
│ to exported.sql      │  Uploads actual schema to S3
└──────┬───────────────┘
       │
       ▼
┌──────────────────────┐
│ Create completion    │  Upload empty file: s3://bucket/prefix/VERSION/completed
│ marker in S3         │  Prevents re-application on next poll
└──────┬───────────────┘
       │
       ▼
┌──────────────────────┐
│ Execute              │  Run success hook (e.g., Slack notification)
│ on-apply-succeeded   │
└──────┬───────────────┘
       │
       ▼
┌──────────────────────┐
│ Release advisory     │  Connection close releases lock automatically
│ lock                 │
└──────────────────────┘
```

**Version Selection:**

The tool uses semantic version comparison to select the latest schema. Supported formats:
- Simple versions: `v1`, `v2`, `v10` (v10 > v9)
- Semver: `1.0.0`, `2.0.0`, `1.10.0`
- Semver with v prefix: `v1.0.0`, `v2.0.0`
- Timestamps: `20240101120000`, `20260120153045`

When multiple versions exist, the highest version is selected and applied if its completion marker doesn't exist.

### Configuration

All options can be set via **environment variables** or **CLI flags**. CLI flags take precedence over environment variables.

#### Global S3 Settings

| Flag | Environment Variable | Description | Required |
|------|---------------------|-------------|----------|
| `--s3-bucket` | `S3_BUCKET` | S3 bucket name containing schema files | Yes |
| `--s3-endpoint` | `S3_ENDPOINT` | Custom S3 endpoint URL for S3-compatible storage | No |
| `--path-prefix` | `PATH_PREFIX` | S3 path prefix (e.g., "schemas/") | Yes |
| `--schema-file` | `SCHEMA_FILE` | Schema file name (default: "schema.sql") | No |
| `--completed-file` | `COMPLETED_FILE` | Completion marker file name (default: "completed") | No |

#### Database Settings (watch/apply only)

| Flag | Environment Variable | Description | Required |
|------|---------------------|-------------|----------|
| `--db-host` | `DB_HOST` | Database host | Yes |
| `--db-port` | `DB_PORT` | Database port | Yes |
| `--db-user` | `DB_USER` | Database user | Yes |
| `--db-password` | `DB_PASSWORD` | Database password | Yes |
| `--db-name` | `DB_NAME` | Database name | Yes |

#### Export Settings (watch/apply only)

| Flag | Environment Variable | Description | Default |
|------|---------------------|-------------|---------|
| `--export-after-apply` | `EXPORT_AFTER_APPLY` | Export schema after successful apply and upload to S3 as `exported.sql` | false |

#### Concurrency Control (watch/apply only)

| Flag | Environment Variable | Description | Default |
|------|---------------------|-------------|---------|
| `--skip-lock` | `SKIP_LOCK` | Skip advisory lock (not recommended for production) | false |

**Advisory Lock:**

When multiple instances of db-schema-sync run against the same database, they use PostgreSQL Advisory Locks to ensure only one instance applies the schema at a time. This prevents race conditions and duplicate schema applications.

- Uses `pg_try_advisory_lock()` for non-blocking lock acquisition
- If another process holds the lock, the current process skips the apply and logs "Another process is applying schema, skipping"
- Lock is automatically released when the connection closes (crash-safe)
- Lock scope is per-database, so different databases can be updated concurrently

**Note:** Use `--skip-lock` only for testing or when you're certain only one instance will run.

#### Watch Mode Settings

| Flag | Environment Variable | Description | Default |
|------|---------------------|-------------|---------|
| `--interval` | `INTERVAL` | Polling interval | 1m |
| `--metrics-addr` | `METRICS_ADDR` | Metrics endpoint address (e.g., `:9090`). Disabled if not set | (disabled) |

#### Prometheus Metrics (watch only)

When `--metrics-addr` is set, the tool exposes Prometheus metrics on the specified address.

**Endpoints:**
- `/metrics` - Prometheus metrics
- `/health` - Health check (returns 200 OK)

**Exposed Metrics:**

| Metric Name | Type | Description |
|-------------|------|-------------|
| `db_schema_sync_apply_total` | Counter | Total number of schema apply attempts |
| `db_schema_sync_apply_success_total` | Counter | Total number of successful schema applies |
| `db_schema_sync_apply_error_total` | Counter | Total number of failed schema applies |
| `db_schema_sync_s3_fetch_total` | Counter | Total number of S3 fetch attempts |
| `db_schema_sync_s3_fetch_error_total` | Counter | Total number of S3 fetch errors |
| `db_schema_sync_consecutive_failures` | Gauge | Current number of consecutive failures |
| `db_schema_sync_last_apply_timestamp_seconds` | Gauge | Unix timestamp of the last successful schema apply |
| `db_schema_sync_process_start_time_seconds` | Gauge | Unix timestamp when the process started |
| `db_schema_sync_last_applied_version_info` | Gauge | Information about the last applied version (with `version` label) |

In addition, the Go Prometheus client automatically exposes `process_*` and `go_*` metrics.

#### Lifecycle Hooks (watch/apply)

| Flag | Environment Variable | Description |
|------|---------------------|-------------|
| `--on-start` | `ON_START` | Command to run when the process starts (watch only) |
| `--on-s3-fetch-error` | `ON_S3_FETCH_ERROR` | Command to run when S3 fetch fails 3 times consecutively (watch only) |
| `--on-before-apply` | `ON_BEFORE_APPLY` | Command to run before schema application starts |
| `--on-apply-failed` | `ON_APPLY_FAILED` | Command to run when schema application fails |
| `--on-apply-succeeded` | `ON_APPLY_SUCCEEDED` | Command to run after schema is successfully applied |

**Hook Environment Variables:**

When hook commands are executed, the following environment variables are available:

| Variable | Description | Hooks |
|----------|-------------|-------|
| `DB_SCHEMA_SYNC_S3_BUCKET` | S3 bucket name | All |
| `DB_SCHEMA_SYNC_PATH_PREFIX` | S3 path prefix | All |
| `DB_SCHEMA_SYNC_SCHEMA_FILE` | Schema file name | All |
| `DB_SCHEMA_SYNC_COMPLETED_FILE` | Completion marker file name | All |
| `DB_SCHEMA_SYNC_VERSION` | Schema version being applied | on-before-apply, on-apply-failed, on-apply-succeeded, on-s3-fetch-error |
| `DB_SCHEMA_SYNC_ERROR` | Error message | on-apply-failed, on-s3-fetch-error |
| `DB_SCHEMA_SYNC_APP_VERSION` | db-schema-sync version | All |
| `DB_SCHEMA_SYNC_STDOUT` | psqldef stdout output | on-apply-failed |
| `DB_SCHEMA_SYNC_STDERR` | psqldef stderr output | on-apply-failed |
| `DB_SCHEMA_SYNC_DRY_RUN` | psqldef --dry-run output (DDL to be applied) | on-before-apply |

**Example Hook:**

```bash
db-schema-sync watch \
  --on-apply-failed 'curl -X POST $SLACK_WEBHOOK_URL -H "Content-Type: application/json" -d "{\"text\":\"❌ Schema apply failed: $DB_SCHEMA_SYNC_ERROR\"}"'
```

#### AWS Credentials

AWS credentials are handled by the AWS SDK and can be configured via:
- `AWS_ACCESS_KEY_ID`: AWS access key ID
- `AWS_SECRET_ACCESS_KEY`: AWS secret access key
- `AWS_SESSION_TOKEN`: AWS session token (if using temporary credentials)
- `AWS_DEFAULT_REGION`: AWS region (optional, defaults to us-east-1)
- IAM roles (when running on EC2, ECS, or EKS)

### Examples

#### Watch mode (daemon):

```bash
db-schema-sync watch \
  --s3-bucket my-bucket \
  --path-prefix schemas/ \
  --db-host localhost \
  --db-port 5432 \
  --db-user user \
  --db-password pass \
  --db-name mydb \
  --interval 30s \
  --on-apply-succeeded "curl -X POST https://my-api/notify"
```

#### Watch mode with Prometheus metrics:

```bash
db-schema-sync watch \
  --s3-bucket my-bucket \
  --path-prefix schemas/ \
  --db-host localhost \
  --db-port 5432 \
  --db-user user \
  --db-password pass \
  --db-name mydb \
  --metrics-addr :9090
```

Metrics are available at `http://localhost:9090/metrics` and health check at `http://localhost:9090/health`.

#### Apply mode (single-shot):

```bash
db-schema-sync apply \
  --s3-bucket my-bucket \
  --path-prefix schemas/ \
  --db-host localhost \
  --db-port 5432 \
  --db-user user \
  --db-password pass \
  --db-name mydb
```

#### Apply mode with schema export:

```bash
db-schema-sync apply \
  --s3-bucket my-bucket \
  --path-prefix schemas/ \
  --db-host localhost \
  --db-port 5432 \
  --db-user user \
  --db-password pass \
  --db-name mydb \
  --export-after-apply
```

This exports the database schema after successful apply and uploads it to S3 as `exported.sql` in the same directory as `schema.sql`.

#### Plan mode (show DDL changes):

```bash
db-schema-sync plan \
  --s3-bucket my-bucket \
  --path-prefix schemas/ \
  schema.sql
```

This shows the DDL changes that would be applied when migrating from the current S3 schema (`exported.sql` or `schema.sql`) to your local `schema.sql` file. Uses psqldef's offline mode, so no database connection is required. Useful for reviewing changes before creating a PR (like `terraform plan`).

#### Fetch completed schema from S3:

```bash
# Output to stdout
db-schema-sync fetch-completed \
  --s3-bucket my-bucket \
  --path-prefix schemas/

# Save to file
db-schema-sync fetch-completed \
  --s3-bucket my-bucket \
  --path-prefix schemas/ \
  -o current-schema.sql
```

This fetches the latest completed schema (`exported.sql` or `schema.sql`) from S3.

#### Using environment variables:

```bash
export S3_BUCKET=my-bucket
export PATH_PREFIX=schemas/
export DB_HOST=localhost
export DB_PORT=5432
export DB_USER=user
export DB_PASSWORD=pass
export DB_NAME=mydb

db-schema-sync watch --interval 30s
```

#### Using Docker:

```bash
docker run \
  -e S3_BUCKET=my-bucket \
  -e PATH_PREFIX=schemas/ \
  -e DB_HOST=localhost \
  -e DB_PORT=5432 \
  -e DB_USER=user \
  -e DB_PASSWORD=pass \
  -e DB_NAME=mydb \
  -e INTERVAL=30s \
  ghcr.io/tokuhirom/db-schema-sync:latest watch
```

## Docker Deployment

### Production Docker Run

**Simple example with inline hook:**

```bash
docker run -d \
  --name db-schema-sync-watch \
  --restart unless-stopped \
  -e S3_BUCKET=my-bucket \
  -e PATH_PREFIX=schemas/ \
  -e DB_HOST=db.example.com \
  -e DB_PORT=5432 \
  -e DB_USER=postgres \
  -e DB_PASSWORD=secret \
  -e DB_NAME=mydb \
  -e INTERVAL=1m \
  -e METRICS_ADDR=:9090 \
  -e EXPORT_AFTER_APPLY=true \
  -e ON_APPLY_SUCCEEDED='curl -X POST $SLACK_WEBHOOK_URL -d "{\"text\":\"Schema $DB_SCHEMA_SYNC_VERSION applied\"}"' \
  -e SLACK_WEBHOOK_URL=https://hooks.slack.com/services/YOUR/WEBHOOK \
  -e AWS_ACCESS_KEY_ID=AKIAIOSFODNN7EXAMPLE \
  -e AWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY \
  -e AWS_DEFAULT_REGION=us-east-1 \
  -p 9090:9090 \
  ghcr.io/tokuhirom/db-schema-sync:latest watch
```

**Advanced example with script files:**

For complex hook logic, mount script files as volumes:

```bash
docker run -d \
  --name db-schema-sync-watch \
  --restart unless-stopped \
  -e S3_BUCKET=my-bucket \
  -e PATH_PREFIX=schemas/ \
  -e DB_HOST=db.example.com \
  -e DB_PORT=5432 \
  -e DB_USER=postgres \
  -e DB_PASSWORD=secret \
  -e DB_NAME=mydb \
  -e INTERVAL=1m \
  -e METRICS_ADDR=:9090 \
  -e EXPORT_AFTER_APPLY=true \
  -e ON_APPLY_SUCCEEDED=/scripts/notify-slack.sh \
  -e ON_APPLY_FAILED=/scripts/notify-slack-error.sh \
  -e SLACK_WEBHOOK_URL=https://hooks.slack.com/services/YOUR/WEBHOOK \
  -e AWS_ACCESS_KEY_ID=AKIAIOSFODNN7EXAMPLE \
  -e AWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY \
  -e AWS_DEFAULT_REGION=us-east-1 \
  -v ./scripts:/scripts:ro \
  -p 9090:9090 \
  ghcr.io/tokuhirom/db-schema-sync:latest watch
```

**Key Configuration:**
- `--restart unless-stopped`: Auto-restart on failure
- `-p 9090:9090`: Expose Prometheus metrics endpoint
- `-v ./scripts:/scripts:ro`: Mount hook scripts (read-only, optional for advanced usage)
- Health check available at `http://localhost:9090/health`

### Sakura Cloud AppRun Deployment

Example configuration for deploying db-schema-sync using [apprun-dedicated-provisioner](https://github.com/tokuhirom/apprun-dedicated-provisioner):

```yaml
# apprun.yaml
clusterName: "your-cluster-name"

applications:
  - name: "db-schema-sync-watch"
    spec:
      # Use the image specified in config
      useConfigImage: true
      image: "ghcr.io/tokuhirom/db-schema-sync:latest"
      cmd: ["watch"]

      # Resource Allocation
      cpu: 500        # mCPU (0.5 cores)
      memory: 512     # MB

      # Scaling Configuration (single instance for watch mode)
      scalingMode: "manual"
      fixedScale: 1   # Only one instance should run per database

      # Expose metrics endpoint (internal only)
      exposedPorts:
        - targetPort: 9090
          loadBalancerPort: null  # No public load balancer
          healthCheck:
            path: "/health"
            intervalSeconds: 30
            timeoutSeconds: 5

      # Environment Variables
      env:
        # S3 Configuration
        - key: "S3_BUCKET"
          value: "my-bucket"
          secret: false
        - key: "PATH_PREFIX"
          value: "schemas/"
          secret: false
        - key: "S3_ENDPOINT"
          value: "https://s3.isk01.sakurastorage.jp"
          secret: false

        # AWS Credentials (secret values)
        - key: "AWS_ACCESS_KEY_ID"
          secret: true
          secretVersion: 1
        - key: "AWS_SECRET_ACCESS_KEY"
          secret: true
          secretVersion: 1

        # Database Configuration
        - key: "DB_HOST"
          value: "db.example.com"
          secret: false
        - key: "DB_PORT"
          value: "5432"
          secret: false
        - key: "DB_USER"
          value: "postgres"
          secret: false
        - key: "DB_NAME"
          value: "mydb"
          secret: false
        - key: "DB_PASSWORD"
          secret: true
          secretVersion: 1

        # Watch Mode Settings
        - key: "INTERVAL"
          value: "1m"
          secret: false
        - key: "METRICS_ADDR"
          value: ":9090"
          secret: false
        - key: "EXPORT_AFTER_APPLY"
          value: "true"
          secret: false

        # Lifecycle Hooks (inline command)
        - key: "ON_APPLY_SUCCEEDED"
          value: 'curl -X POST $SLACK_WEBHOOK_URL -d "{\"text\":\"Schema applied\"}"'
          secret: false
        - key: "SLACK_WEBHOOK_URL"
          secret: true
          secretVersion: 1
```

**Key Points:**

1. **Single Instance**: `fixedScale: 1` ensures only one watch container runs (prevents concurrent applies)
2. **Secret Management**: Use `secret: true` + `secretVersion` for sensitive values
3. **Health Check**: Monitors `/health` endpoint for container health
4. **No Public LB**: `loadBalancerPort: null` keeps metrics internal
5. **S3 Endpoint**: Use Sakura Cloud's S3 endpoint for best performance

**Monitoring:**

Access metrics from another container in the same cluster:
```bash
curl http://db-schema-sync-watch:9090/metrics
curl http://db-schema-sync-watch:9090/health
```

#### Using S3-compatible storage (e.g., Sakura Cloud, MinIO):

```bash
db-schema-sync watch \
  --s3-endpoint https://s3.isk01.sakurastorage.jp \
  --s3-bucket my-bucket \
  --path-prefix schemas/ \
  --db-host localhost \
  --db-port 5432 \
  --db-user user \
  --db-password pass \
  --db-name mydb
```

## GitHub Actions Integration

Integrate db-schema-sync into your CI/CD pipeline for automated schema management. Below are complete, copy-paste-ready examples for common workflows.

### Example 1: PR Schema Diff Comment

Automatically post DDL changes as a PR comment when `schema.sql` is modified. This gives reviewers visibility into exactly what database changes will be applied.

```yaml
# .github/workflows/schema-diff.yml
name: Schema Diff on PR

on:
  pull_request:
    paths:
      - 'schema.sql'

jobs:
  schema-diff:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pull-requests: write  # Required to post PR comments

    steps:
      - name: Checkout PR branch
        uses: actions/checkout@v4

      - name: Generate schema diff
        id: diff
        run: |
          # Run plan command and capture output
          docker run --rm \
            -e AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }} \
            -e AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }} \
            -e AWS_DEFAULT_REGION=us-east-1 \
            -v $(pwd):/work \
            ghcr.io/tokuhirom/db-schema-sync:latest \
            plan \
            --s3-bucket ${{ secrets.S3_BUCKET }} \
            --path-prefix schemas/ \
            /work/schema.sql > diff.txt 2>&1 || true

          # Create formatted comment body
          echo "DIFF<<EOF" >> $GITHUB_OUTPUT
          echo "## Database Schema Changes" >> $GITHUB_OUTPUT
          echo "" >> $GITHUB_OUTPUT
          echo "\`\`\`sql" >> $GITHUB_OUTPUT
          cat diff.txt >> $GITHUB_OUTPUT
          echo "\`\`\`" >> $GITHUB_OUTPUT
          echo "" >> $GITHUB_OUTPUT
          echo "These DDL changes will be applied when this PR is merged and deployed." >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Post diff as PR comment
        uses: actions/github-script@v7
        with:
          script: |
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: process.env.DIFF
            })
        env:
          DIFF: ${{ steps.diff.outputs.DIFF }}
```

### Example 2: Upload Schema to S3 on Merge

Automatically upload the schema file to S3 with timestamp versioning when changes are merged to main.

```yaml
# .github/workflows/upload-schema.yml
name: Upload Schema to S3

on:
  push:
    branches:
      - main
    paths:
      - 'schema.sql'
  workflow_dispatch:  # Allow manual trigger

jobs:
  upload-schema:
    runs-on: ubuntu-latest
    permissions:
      contents: read

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Generate timestamp version
        id: version
        run: |
          # Format: YYYYMMDDHHMMSS (e.g., 20260120153045)
          VERSION=$(date -u +%Y%m%d%H%M%S)
          echo "version=$VERSION" >> $GITHUB_OUTPUT
          echo "Generated version: $VERSION"

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Upload schema.sql to S3
        run: |
          VERSION=${{ steps.version.outputs.version }}
          S3_PATH="s3://${{ secrets.S3_BUCKET }}/schemas/$VERSION/schema.sql"

          echo "Uploading to $S3_PATH"
          aws s3 cp schema.sql "$S3_PATH"

          echo "✅ Schema uploaded successfully"
          echo "Version: $VERSION"
          echo "Path: $S3_PATH"

      - name: Post deployment notification (optional)
        if: success()
        run: |
          echo "Schema version ${{ steps.version.outputs.version }} uploaded to S3"
          echo "The watch container will apply this schema automatically"
          # Add Slack/Teams notification here if needed
```

### Lifecycle Hook Examples for Production

**Example with inline command:**
```bash
docker run -d \
  -e ON_APPLY_SUCCEEDED='curl -X POST $SLACK_WEBHOOK_URL -H "Content-Type: application/json" -d "{\"text\":\"Schema $DB_SCHEMA_SYNC_VERSION applied\"}"' \
  -e SLACK_WEBHOOK_URL=https://hooks.slack.com/services/YOUR/WEBHOOK/URL \
  ghcr.io/tokuhirom/db-schema-sync:latest watch
```

## Version Formats

The tool supports semantic version comparison. Supported formats:
- Simple versions: `v1`, `v2`, `v10` (v10 > v9)
- Semver: `1.0.0`, `2.0.0`, `1.10.0`
- Semver with v prefix: `v1.0.0`, `v2.0.0`
- Timestamps: `20240101120000`

## Development

### Build

```bash
make build
```

### Test

```bash
# Run unit tests
make test

# Run integration tests (requires Docker)
make test-integration
```

### Lint

```bash
make lint
```
