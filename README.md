# DB Schema Sync

A tool to synchronize database schemas from S3 using psqldef.

## What is db-schema-sync?

**db-schema-sync** is a declarative database schema management tool - think "Terraform for databases". Instead of writing migration files, you define your desired schema state in a single `schema.sql` file, and the tool automatically generates and applies the necessary ALTER queries to reconcile any differences.

**Key Concepts:**

- **Declarative approach**: You declare the desired state (what tables, columns, indexes you want), not the migration steps
- **Powered by psqldef**: Automatically generates safe DDL (ALTER TABLE, CREATE INDEX, etc.) by comparing current database state with your schema file
- **S3 as source of truth**: Schema versions are stored in S3, enabling GitOps workflows and centralized schema management
- **Safe concurrent applies**: PostgreSQL advisory locks prevent multiple instances from applying schemas simultaneously
- **Production-ready**: Built-in lifecycle hooks, Prometheus metrics, error handling, and schema export capabilities

**How it differs from traditional migrations:**

| Traditional Migrations | db-schema-sync |
|------------------------|----------------|
| Write sequential migration files | Define desired state in schema.sql |
| Manually write ALTER queries | Auto-generated by psqldef |
| Migration history in application | Schema versions in S3 |
| Must replay all migrations | Direct application of target state |

## Typical Workflow

db-schema-sync enables a complete CI/CD workflow for database schema management:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Developer modifies schema.sql in Git repository                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. GitHub Actions: PR opened                                       â”‚
â”‚     â€¢ Fetch current schema from S3                                 â”‚
â”‚     â€¢ Run: db-schema-sync plan schema.sql                          â”‚
â”‚     â€¢ Post DDL diff as PR comment (shows ALTER queries)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. Review & Merge PR                                               â”‚
â”‚     â€¢ Team reviews DDL changes in PR comment                        â”‚
â”‚     â€¢ Approves and merges                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. GitHub Actions: Post-merge                                      â”‚
â”‚     â€¢ Generate version (timestamp: 20260120153045)                  â”‚
â”‚     â€¢ Upload schema.sql to S3: s3://bucket/schemas/v20260120153045/ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. Watch Container (running in production)                         â”‚
â”‚     â€¢ Polls S3 every minute                                         â”‚
â”‚     â€¢ Detects new version: v20260120153045                          â”‚
â”‚     â€¢ Acquires PostgreSQL advisory lock                             â”‚
â”‚     â€¢ Applies schema via psqldef                                    â”‚
â”‚     â€¢ Exports applied schema to S3                                  â”‚
â”‚     â€¢ Creates completion marker                                     â”‚
â”‚     â€¢ Executes on-apply-succeeded hook                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  6. Notification (via lifecycle hook)                               â”‚
â”‚     â€¢ Slack notification: "Schema v20260120153045 applied"          â”‚
â”‚     â€¢ Includes DDL diff and success/failure status                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Benefits of this workflow:**

- **Visibility**: Team sees exact DDL changes before merge
- **Safety**: Review process catches breaking changes early
- **Automation**: No manual schema application steps
- **Auditability**: S3 versions provide complete schema history
- **Rollback-ready**: Previous versions remain in S3 for rollback scenarios

See the [GitHub Actions Integration](#github-actions-integration) section for complete implementation examples.

## Features

- Periodically polls S3 for schema file updates (watch mode)
- Single-shot schema application (apply mode)
- Plan mode for offline schema comparison (plan mode)
- Fetch latest completed schema from S3 (fetch-completed mode)
- Export schema after apply and upload to S3
- Semantic version sorting for schema versions
- Uses psqldef for safe schema migrations
- Lifecycle hooks for startup, success, and error notifications
- Flexible configuration via environment variables or CLI flags
- S3-compatible storage support (Sakura Cloud, MinIO, etc.)
- Dockerized for easy deployment

## License

This project is licensed under the MIT License.

## Usage

### Subcommands

```
db-schema-sync watch            # Run in daemon mode, continuously polling for schema updates
db-schema-sync apply            # Apply schema once and exit
db-schema-sync plan             # Show DDL changes between S3 schema and local file (like terraform plan)
db-schema-sync fetch-completed  # Fetch latest completed schema from S3
```

### How it works

This tool monitors an S3 bucket for schema file updates. Schema files are organized in S3 with version-based directories:

**S3 Bucket Structure:**

```
s3://my-bucket/schemas/
â”œâ”€â”€ v1/
â”‚   â”œâ”€â”€ schema.sql           # Desired schema state
â”‚   â”œâ”€â”€ completed            # Marker file (created after successful apply)
â”‚   â””â”€â”€ exported.sql         # Actual schema after apply (optional)
â”œâ”€â”€ v2/
â”‚   â”œâ”€â”€ schema.sql
â”‚   â”œâ”€â”€ completed
â”‚   â””â”€â”€ exported.sql
â”œâ”€â”€ 20260115120000/          # Timestamp version
â”‚   â”œâ”€â”€ schema.sql
â”‚   â”œâ”€â”€ completed
â”‚   â””â”€â”€ exported.sql
â””â”€â”€ 20260120153045/          # Latest version
    â”œâ”€â”€ schema.sql           # â† This will be applied
    â”œâ”€â”€ completed            # â† Created after apply
    â””â”€â”€ exported.sql         # â† Exported schema (if enabled)
```

**Path Configuration:**
- **Bucket**: `my-bucket` (set via `--s3-bucket` or `S3_BUCKET`)
- **Path prefix**: `schemas/` (set via `--path-prefix` or `PATH_PREFIX`)
- **Version**: Semantic version (`v1`, `v2.1.0`) or timestamp (`20260120153045`)
- **Schema file**: `schema.sql` (configurable via `--schema-file`)
- **Completion marker**: `completed` (configurable via `--completed-file`)

**Watch Mode Operation:**

The tool continuously polls S3 and applies new schemas when detected:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Poll S3      â”‚  Every --interval (default: 1m)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ List all versions    â”‚  Find highest version using semver comparison
â”‚ s3://bucket/prefix/  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Check if completed   â”‚  Skip if completion marker exists
â”‚ marker exists        â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ New version detected
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Acquire advisory     â”‚  pg_try_advisory_lock() - prevents concurrent applies
â”‚ lock on PostgreSQL   â”‚  If locked by another instance, skip and log
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Download schema.sql  â”‚  From s3://bucket/prefix/VERSION/schema.sql
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Execute              â”‚  Run hook script if configured
â”‚ on-before-apply hook â”‚  (receives DDL diff via DB_SCHEMA_SYNC_DRY_RUN)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Apply via psqldef    â”‚  psqldef generates and executes ALTER queries
â”‚                      â”‚  Compares desired state vs current database
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Export schema        â”‚  If --export-after-apply is set
â”‚ to exported.sql      â”‚  Uploads actual schema to S3
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Create completion    â”‚  Upload empty file: s3://bucket/prefix/VERSION/completed
â”‚ marker in S3         â”‚  Prevents re-application on next poll
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Execute              â”‚  Run success hook (e.g., Slack notification)
â”‚ on-apply-succeeded   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Release advisory     â”‚  Connection close releases lock automatically
â”‚ lock                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Version Selection:**

The tool uses semantic version comparison to select the latest schema. Supported formats:
- Simple versions: `v1`, `v2`, `v10` (v10 > v9)
- Semver: `1.0.0`, `2.0.0`, `1.10.0`
- Semver with v prefix: `v1.0.0`, `v2.0.0`
- Timestamps: `20240101120000`, `20260120153045`

When multiple versions exist, the highest version is selected and applied if its completion marker doesn't exist.

### Configuration

All options can be set via **environment variables** or **CLI flags**. CLI flags take precedence over environment variables.

#### Global S3 Settings

| Flag | Environment Variable | Description | Required |
|------|---------------------|-------------|----------|
| `--s3-bucket` | `S3_BUCKET` | S3 bucket name containing schema files | Yes |
| `--s3-endpoint` | `S3_ENDPOINT` | Custom S3 endpoint URL for S3-compatible storage | No |
| `--path-prefix` | `PATH_PREFIX` | S3 path prefix (e.g., "schemas/") | Yes |
| `--schema-file` | `SCHEMA_FILE` | Schema file name (default: "schema.sql") | No |
| `--completed-file` | `COMPLETED_FILE` | Completion marker file name (default: "completed") | No |

#### Database Settings (watch/apply only)

| Flag | Environment Variable | Description | Required |
|------|---------------------|-------------|----------|
| `--db-host` | `DB_HOST` | Database host | Yes |
| `--db-port` | `DB_PORT` | Database port | Yes |
| `--db-user` | `DB_USER` | Database user | Yes |
| `--db-password` | `DB_PASSWORD` | Database password | Yes |
| `--db-name` | `DB_NAME` | Database name | Yes |

#### Export Settings (watch/apply only)

| Flag | Environment Variable | Description | Default |
|------|---------------------|-------------|---------|
| `--export-after-apply` | `EXPORT_AFTER_APPLY` | Export schema after successful apply and upload to S3 as `exported.sql` | false |

#### Concurrency Control (watch/apply only)

| Flag | Environment Variable | Description | Default |
|------|---------------------|-------------|---------|
| `--skip-lock` | `SKIP_LOCK` | Skip advisory lock (not recommended for production) | false |

**Advisory Lock:**

When multiple instances of db-schema-sync run against the same database, they use PostgreSQL Advisory Locks to ensure only one instance applies the schema at a time. This prevents race conditions and duplicate schema applications.

- Uses `pg_try_advisory_lock()` for non-blocking lock acquisition
- If another process holds the lock, the current process skips the apply and logs "Another process is applying schema, skipping"
- Lock is automatically released when the connection closes (crash-safe)
- Lock scope is per-database, so different databases can be updated concurrently

**Note:** Use `--skip-lock` only for testing or when you're certain only one instance will run.

#### Watch Mode Settings

| Flag | Environment Variable | Description | Default |
|------|---------------------|-------------|---------|
| `--interval` | `INTERVAL` | Polling interval | 1m |
| `--metrics-addr` | `METRICS_ADDR` | Metrics endpoint address (e.g., `:9090`). Disabled if not set | (disabled) |

#### Prometheus Metrics (watch only)

When `--metrics-addr` is set, the tool exposes Prometheus metrics on the specified address.

**Endpoints:**
- `/metrics` - Prometheus metrics
- `/health` - Health check (returns 200 OK)

**Exposed Metrics:**

| Metric Name | Type | Description |
|-------------|------|-------------|
| `db_schema_sync_apply_total` | Counter | Total number of schema apply attempts |
| `db_schema_sync_apply_success_total` | Counter | Total number of successful schema applies |
| `db_schema_sync_apply_error_total` | Counter | Total number of failed schema applies |
| `db_schema_sync_s3_fetch_total` | Counter | Total number of S3 fetch attempts |
| `db_schema_sync_s3_fetch_error_total` | Counter | Total number of S3 fetch errors |
| `db_schema_sync_consecutive_failures` | Gauge | Current number of consecutive failures |
| `db_schema_sync_last_apply_timestamp_seconds` | Gauge | Unix timestamp of the last successful schema apply |
| `db_schema_sync_process_start_time_seconds` | Gauge | Unix timestamp when the process started |
| `db_schema_sync_last_applied_version_info` | Gauge | Information about the last applied version (with `version` label) |

In addition, the Go Prometheus client automatically exposes `process_*` and `go_*` metrics.

#### Lifecycle Hooks (watch/apply)

| Flag | Environment Variable | Description |
|------|---------------------|-------------|
| `--on-start` | `ON_START` | Command to run when the process starts (watch only) |
| `--on-s3-fetch-error` | `ON_S3_FETCH_ERROR` | Command to run when S3 fetch fails 3 times consecutively (watch only) |
| `--on-before-apply` | `ON_BEFORE_APPLY` | Command to run before schema application starts |
| `--on-apply-failed` | `ON_APPLY_FAILED` | Command to run when schema application fails |
| `--on-apply-succeeded` | `ON_APPLY_SUCCEEDED` | Command to run after schema is successfully applied |

**Hook Environment Variables:**

When hook commands are executed, the following environment variables are available:

| Variable | Description | Hooks |
|----------|-------------|-------|
| `DB_SCHEMA_SYNC_S3_BUCKET` | S3 bucket name | All |
| `DB_SCHEMA_SYNC_PATH_PREFIX` | S3 path prefix | All |
| `DB_SCHEMA_SYNC_SCHEMA_FILE` | Schema file name | All |
| `DB_SCHEMA_SYNC_COMPLETED_FILE` | Completion marker file name | All |
| `DB_SCHEMA_SYNC_VERSION` | Schema version being applied | on-before-apply, on-apply-failed, on-apply-succeeded, on-s3-fetch-error |
| `DB_SCHEMA_SYNC_ERROR` | Error message | on-apply-failed, on-s3-fetch-error |
| `DB_SCHEMA_SYNC_APP_VERSION` | db-schema-sync version | All |
| `DB_SCHEMA_SYNC_STDOUT` | psqldef stdout output | on-apply-failed |
| `DB_SCHEMA_SYNC_STDERR` | psqldef stderr output | on-apply-failed |
| `DB_SCHEMA_SYNC_DRY_RUN` | psqldef --dry-run output (DDL to be applied) | on-before-apply |

**Example Hooks:**

**Simple Slack notification (one-liner):**
```bash
db-schema-sync watch \
  --on-apply-succeeded 'curl -X POST $SLACK_WEBHOOK_URL -H "Content-Type: application/json" -d "{\"text\":\"Schema $DB_SCHEMA_SYNC_VERSION applied successfully\"}"'
```

**Using a shell script file:**
```bash
# Create a script file for complex logic
cat > /usr/local/bin/notify-slack.sh <<'EOF'
#!/bin/bash
curl -X POST "$SLACK_WEBHOOK_URL" \
  -H 'Content-Type: application/json' \
  -d "{\"text\":\"âœ… Schema $DB_SCHEMA_SYNC_VERSION applied to $DB_NAME\"}"
EOF
chmod +x /usr/local/bin/notify-slack.sh

# Reference the script file in the hook
db-schema-sync watch \
  --on-apply-succeeded /usr/local/bin/notify-slack.sh
```

**Log to file:**
```bash
db-schema-sync watch \
  --on-apply-succeeded 'echo "$(date): Applied schema $DB_SCHEMA_SYNC_VERSION" >> /var/log/schema-sync.log'
```

**Error notification:**
```bash
db-schema-sync watch \
  --on-apply-failed 'curl -X POST $SLACK_WEBHOOK_URL -H "Content-Type: application/json" -d "{\"text\":\"âŒ Schema apply failed: $DB_SCHEMA_SYNC_ERROR\"}"'
```

**Multiple commands (using semicolon or &&):**
```bash
db-schema-sync watch \
  --on-apply-succeeded 'logger "Schema $DB_SCHEMA_SYNC_VERSION applied"; curl -X POST $SLACK_WEBHOOK_URL -d "{\"text\":\"Done\"}"'
```

#### AWS Credentials

AWS credentials are handled by the AWS SDK and can be configured via:
- `AWS_ACCESS_KEY_ID`: AWS access key ID
- `AWS_SECRET_ACCESS_KEY`: AWS secret access key
- `AWS_SESSION_TOKEN`: AWS session token (if using temporary credentials)
- `AWS_DEFAULT_REGION`: AWS region (optional, defaults to us-east-1)
- IAM roles (when running on EC2, ECS, or EKS)

### Examples

#### Watch mode (daemon):

```bash
db-schema-sync watch \
  --s3-bucket my-bucket \
  --path-prefix schemas/ \
  --db-host localhost \
  --db-port 5432 \
  --db-user user \
  --db-password pass \
  --db-name mydb \
  --interval 30s \
  --on-apply-succeeded "curl -X POST https://my-api/notify"
```

#### Watch mode with Prometheus metrics:

```bash
db-schema-sync watch \
  --s3-bucket my-bucket \
  --path-prefix schemas/ \
  --db-host localhost \
  --db-port 5432 \
  --db-user user \
  --db-password pass \
  --db-name mydb \
  --metrics-addr :9090
```

Metrics are available at `http://localhost:9090/metrics` and health check at `http://localhost:9090/health`.

#### Apply mode (single-shot):

```bash
db-schema-sync apply \
  --s3-bucket my-bucket \
  --path-prefix schemas/ \
  --db-host localhost \
  --db-port 5432 \
  --db-user user \
  --db-password pass \
  --db-name mydb
```

#### Apply mode with schema export:

```bash
db-schema-sync apply \
  --s3-bucket my-bucket \
  --path-prefix schemas/ \
  --db-host localhost \
  --db-port 5432 \
  --db-user user \
  --db-password pass \
  --db-name mydb \
  --export-after-apply
```

This exports the database schema after successful apply and uploads it to S3 as `exported.sql` in the same directory as `schema.sql`.

#### Plan mode (show DDL changes):

```bash
db-schema-sync plan \
  --s3-bucket my-bucket \
  --path-prefix schemas/ \
  schema.sql
```

This shows the DDL changes that would be applied when migrating from the current S3 schema (`exported.sql` or `schema.sql`) to your local `schema.sql` file. Uses psqldef's offline mode, so no database connection is required. Useful for reviewing changes before creating a PR (like `terraform plan`).

#### Fetch completed schema from S3:

```bash
# Output to stdout
db-schema-sync fetch-completed \
  --s3-bucket my-bucket \
  --path-prefix schemas/

# Save to file
db-schema-sync fetch-completed \
  --s3-bucket my-bucket \
  --path-prefix schemas/ \
  -o current-schema.sql
```

This fetches the latest completed schema (`exported.sql` or `schema.sql`) from S3.

#### Using environment variables:

```bash
export S3_BUCKET=my-bucket
export PATH_PREFIX=schemas/
export DB_HOST=localhost
export DB_PORT=5432
export DB_USER=user
export DB_PASSWORD=pass
export DB_NAME=mydb

db-schema-sync watch --interval 30s
```

#### Using Docker:

```bash
docker run \
  -e S3_BUCKET=my-bucket \
  -e PATH_PREFIX=schemas/ \
  -e DB_HOST=localhost \
  -e DB_PORT=5432 \
  -e DB_USER=user \
  -e DB_PASSWORD=pass \
  -e DB_NAME=mydb \
  -e INTERVAL=30s \
  ghcr.io/tokuhirom/db-schema-sync:latest watch
```

## Docker Deployment

### Production Docker Run

**Simple example with inline hook:**

```bash
docker run -d \
  --name db-schema-sync-watch \
  --restart unless-stopped \
  -e S3_BUCKET=my-bucket \
  -e PATH_PREFIX=schemas/ \
  -e DB_HOST=db.example.com \
  -e DB_PORT=5432 \
  -e DB_USER=postgres \
  -e DB_PASSWORD=secret \
  -e DB_NAME=mydb \
  -e INTERVAL=1m \
  -e METRICS_ADDR=:9090 \
  -e EXPORT_AFTER_APPLY=true \
  -e ON_APPLY_SUCCEEDED='curl -X POST $SLACK_WEBHOOK_URL -d "{\"text\":\"Schema $DB_SCHEMA_SYNC_VERSION applied\"}"' \
  -e SLACK_WEBHOOK_URL=https://hooks.slack.com/services/YOUR/WEBHOOK \
  -e AWS_ACCESS_KEY_ID=AKIAIOSFODNN7EXAMPLE \
  -e AWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY \
  -e AWS_DEFAULT_REGION=us-east-1 \
  -p 9090:9090 \
  ghcr.io/tokuhirom/db-schema-sync:latest watch
```

**Advanced example with script files:**

For complex hook logic, mount script files as volumes:

```bash
docker run -d \
  --name db-schema-sync-watch \
  --restart unless-stopped \
  -e S3_BUCKET=my-bucket \
  -e PATH_PREFIX=schemas/ \
  -e DB_HOST=db.example.com \
  -e DB_PORT=5432 \
  -e DB_USER=postgres \
  -e DB_PASSWORD=secret \
  -e DB_NAME=mydb \
  -e INTERVAL=1m \
  -e METRICS_ADDR=:9090 \
  -e EXPORT_AFTER_APPLY=true \
  -e ON_APPLY_SUCCEEDED=/scripts/notify-slack.sh \
  -e ON_APPLY_FAILED=/scripts/notify-slack-error.sh \
  -e SLACK_WEBHOOK_URL=https://hooks.slack.com/services/YOUR/WEBHOOK \
  -e AWS_ACCESS_KEY_ID=AKIAIOSFODNN7EXAMPLE \
  -e AWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY \
  -e AWS_DEFAULT_REGION=us-east-1 \
  -v ./scripts:/scripts:ro \
  -p 9090:9090 \
  ghcr.io/tokuhirom/db-schema-sync:latest watch
```

**Key Configuration:**
- `--restart unless-stopped`: Auto-restart on failure
- `-p 9090:9090`: Expose Prometheus metrics endpoint
- `-v ./scripts:/scripts:ro`: Mount hook scripts (read-only, optional for advanced usage)
- Health check available at `http://localhost:9090/health`

### Docker Compose

```yaml
# docker-compose.yml
version: '3.8'

services:
  db-schema-sync:
    image: ghcr.io/tokuhirom/db-schema-sync:latest
    command: watch
    restart: unless-stopped

    environment:
      # S3 Configuration
      S3_BUCKET: my-bucket
      PATH_PREFIX: schemas/
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      AWS_DEFAULT_REGION: us-east-1

      # Database Configuration
      DB_HOST: postgres
      DB_PORT: 5432
      DB_USER: postgres
      DB_PASSWORD: ${DB_PASSWORD}
      DB_NAME: mydb

      # Watch Mode Settings
      INTERVAL: 1m
      METRICS_ADDR: :9090
      EXPORT_AFTER_APPLY: "true"

      # Lifecycle Hooks (using script files)
      ON_APPLY_SUCCEEDED: /scripts/notify-slack.sh
      ON_APPLY_FAILED: /scripts/notify-slack-error.sh
      SLACK_WEBHOOK_URL: ${SLACK_WEBHOOK_URL}
      # Or use inline commands:
      # ON_APPLY_SUCCEEDED: 'curl -X POST $SLACK_WEBHOOK_URL -d "{\"text\":\"Done\"}"'

    volumes:
      - ./scripts:/scripts:ro  # Optional: only needed if using script files

    ports:
      - "9090:9090"

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9090/health"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s

    depends_on:
      - postgres

  postgres:
    image: postgres:16
    environment:
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_DB: mydb
    volumes:
      - postgres-data:/var/lib/postgresql/data
    ports:
      - "5432:5432"

volumes:
  postgres-data:
```

### Sakura Cloud AppRun Deployment

Example configuration for deploying the watch container in Sakura Cloud's AppRun service:

```yaml
# apprun-config.yml
apiVersion: apprun.sakura.ad.jp/v1alpha1
kind: Application
metadata:
  name: db-schema-sync-watch
spec:
  # Container Configuration
  image: ghcr.io/tokuhirom/db-schema-sync:latest
  command: ["watch"]

  # Resource Allocation
  cpu: 500        # mCPU (0.5 cores)
  memory: 512     # MB

  # Scaling Configuration
  scalingMode: manual
  fixedScale: 1   # Single instance (watch mode should run only once per database)

  # Health Check
  healthCheck:
    path: /health
    port: 9090
    intervalSeconds: 30
    timeoutSeconds: 5
    failureThreshold: 3
    initialDelaySeconds: 10

  # Network Configuration
  ports:
    - name: metrics
      containerPort: 9090
      protocol: TCP
      # No public load balancer - internal only
      loadBalancer: null

  # Environment Variables
  env:
    # S3 Configuration
    - name: S3_BUCKET
      value: my-bucket
    - name: PATH_PREFIX
      value: schemas/
    - name: S3_ENDPOINT
      value: https://s3.isk01.sakurastorage.jp

    # AWS Credentials (using AppRun secrets)
    - name: AWS_ACCESS_KEY_ID
      valueFrom:
        secretKeyRef:
          name: aws-credentials
          key: access_key_id
    - name: AWS_SECRET_ACCESS_KEY
      valueFrom:
        secretKeyRef:
          name: aws-credentials
          key: secret_access_key

    # Database Configuration
    - name: DB_HOST
      value: db.example.com
    - name: DB_PORT
      value: "5432"
    - name: DB_USER
      value: postgres
    - name: DB_NAME
      value: mydb
    - name: DB_PASSWORD
      valueFrom:
        secretKeyRef:
          name: db-credentials
          key: password

    # Watch Mode Settings
    - name: INTERVAL
      value: 1m
    - name: METRICS_ADDR
      value: :9090
    - name: EXPORT_AFTER_APPLY
      value: "true"

    # Lifecycle Hooks (if using custom image with scripts)
    # - name: ON_APPLY_SUCCEEDED
    #   value: /scripts/notify-slack.sh
    # - name: SLACK_WEBHOOK_URL
    #   valueFrom:
    #     secretKeyRef:
    #       name: slack-credentials
    #       key: webhook_url

---
# Secrets (create these separately via AppRun console or CLI)
apiVersion: v1
kind: Secret
metadata:
  name: aws-credentials
type: Opaque
stringData:
  access_key_id: AKIAIOSFODNN7EXAMPLE
  secret_access_key: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY

---
apiVersion: v1
kind: Secret
metadata:
  name: db-credentials
type: Opaque
stringData:
  password: your-db-password

---
apiVersion: v1
kind: Secret
metadata:
  name: slack-credentials
type: Opaque
stringData:
  webhook_url: https://hooks.slack.com/services/YOUR/WEBHOOK/URL
```

**Key Points for AppRun Deployment:**

1. **Single Replica**: Set `fixedScale: 1` to ensure only one instance runs (prevents concurrent schema applies)
2. **Health Check**: Uses the `/health` endpoint on port 9090
3. **Internal Metrics**: Metrics port is not exposed to public load balancer
4. **Secrets Management**: Credentials stored in AppRun secrets, not in config
5. **S3 Endpoint**: Use Sakura Cloud's S3 endpoint for optimal performance
6. **Resource Sizing**: 500 mCPU / 512 MB is typically sufficient for watch mode

**Monitoring:**

Access metrics internally via:
```bash
# From another container in the same AppRun network
curl http://db-schema-sync-watch:9090/metrics
```

**Updating Schema:**

1. Upload new schema version to S3 (via GitHub Actions or manual)
2. Watch container detects change within `INTERVAL` period
3. Applies schema automatically
4. Check logs in AppRun console for apply status

#### Using S3-compatible storage (e.g., Sakura Cloud, MinIO):

```bash
db-schema-sync watch \
  --s3-endpoint https://s3.isk01.sakurastorage.jp \
  --s3-bucket my-bucket \
  --path-prefix schemas/ \
  --db-host localhost \
  --db-port 5432 \
  --db-user user \
  --db-password pass \
  --db-name mydb
```

## GitHub Actions Integration

Integrate db-schema-sync into your CI/CD pipeline for automated schema management. Below are complete, copy-paste-ready examples for common workflows.

### Example 1: PR Schema Diff Comment

Automatically post DDL changes as a PR comment when `schema.sql` is modified. This gives reviewers visibility into exactly what database changes will be applied.

```yaml
# .github/workflows/schema-diff.yml
name: Schema Diff on PR

on:
  pull_request:
    paths:
      - 'schema.sql'

jobs:
  schema-diff:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pull-requests: write  # Required to post PR comments

    steps:
      - name: Checkout PR branch
        uses: actions/checkout@v4

      - name: Download db-schema-sync
        run: |
          curl -L -o db-schema-sync https://github.com/tokuhirom/db-schema-sync/releases/latest/download/db-schema-sync-linux-amd64
          chmod +x db-schema-sync

      - name: Fetch current schema from S3
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-east-1
        run: |
          ./db-schema-sync fetch-completed \
            --s3-bucket ${{ secrets.S3_BUCKET }} \
            --path-prefix schemas/ \
            -o current-schema.sql

      - name: Generate schema diff
        id: diff
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-east-1
        run: |
          # Run plan command and capture output
          ./db-schema-sync plan \
            --s3-bucket ${{ secrets.S3_BUCKET }} \
            --path-prefix schemas/ \
            schema.sql > diff.txt 2>&1 || true

          # Create formatted comment body
          echo "DIFF<<EOF" >> $GITHUB_OUTPUT
          echo "## Database Schema Changes" >> $GITHUB_OUTPUT
          echo "" >> $GITHUB_OUTPUT
          echo "\`\`\`sql" >> $GITHUB_OUTPUT
          cat diff.txt >> $GITHUB_OUTPUT
          echo "\`\`\`" >> $GITHUB_OUTPUT
          echo "" >> $GITHUB_OUTPUT
          echo "These DDL changes will be applied when this PR is merged and deployed." >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Post diff as PR comment
        uses: actions/github-script@v7
        with:
          script: |
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: process.env.DIFF
            })
        env:
          DIFF: ${{ steps.diff.outputs.DIFF }}
```

### Example 2: Upload Schema to S3 on Merge

Automatically upload the schema file to S3 with timestamp versioning when changes are merged to main.

```yaml
# .github/workflows/upload-schema.yml
name: Upload Schema to S3

on:
  push:
    branches:
      - main
    paths:
      - 'schema.sql'
  workflow_dispatch:  # Allow manual trigger

jobs:
  upload-schema:
    runs-on: ubuntu-latest
    permissions:
      contents: read

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Generate timestamp version
        id: version
        run: |
          # Format: YYYYMMDDHHMMSS (e.g., 20260120153045)
          VERSION=$(date -u +%Y%m%d%H%M%S)
          echo "version=$VERSION" >> $GITHUB_OUTPUT
          echo "Generated version: $VERSION"

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Upload schema.sql to S3
        run: |
          VERSION=${{ steps.version.outputs.version }}
          S3_PATH="s3://${{ secrets.S3_BUCKET }}/schemas/$VERSION/schema.sql"

          echo "Uploading to $S3_PATH"
          aws s3 cp schema.sql "$S3_PATH"

          echo "âœ… Schema uploaded successfully"
          echo "Version: $VERSION"
          echo "Path: $S3_PATH"

      - name: Post deployment notification (optional)
        if: success()
        run: |
          echo "Schema version ${{ steps.version.outputs.version }} uploaded to S3"
          echo "The watch container will apply this schema automatically"
          # Add Slack/Teams notification here if needed
```

### Example 3: Complete CI/CD Pipeline

Combined workflow showing schema validation, diff preview, and conditional upload.

```yaml
# .github/workflows/schema-ci.yml
name: Schema CI/CD

on:
  pull_request:
    paths: ['schema.sql']
  push:
    branches: [main]
    paths: ['schema.sql']

jobs:
  # Job 1: Validate and preview changes (runs on PR)
  validate-and-preview:
    if: github.event_name == 'pull_request'
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pull-requests: write

    steps:
      - uses: actions/checkout@v4

      - name: Setup db-schema-sync
        run: |
          curl -L -o db-schema-sync https://github.com/tokuhirom/db-schema-sync/releases/latest/download/db-schema-sync-linux-amd64
          chmod +x db-schema-sync
          sudo mv db-schema-sync /usr/local/bin/

      - name: Validate schema.sql syntax
        run: |
          # Basic syntax check (requires psqldef)
          if ! command -v psqldef &> /dev/null; then
            curl -L -o psqldef.tar.gz https://github.com/k0kubun/sqldef/releases/latest/download/psqldef_linux_amd64.tar.gz
            tar xzf psqldef.tar.gz
            chmod +x psqldef
            sudo mv psqldef /usr/local/bin/
          fi

          # Check if schema.sql has valid SQL syntax
          echo "Validating schema.sql syntax..."
          psqldef --help > /dev/null

      - name: Generate and post diff
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        run: |
          db-schema-sync plan \
            --s3-bucket ${{ secrets.S3_BUCKET }} \
            --path-prefix schemas/ \
            schema.sql > diff.txt 2>&1 || true

          # Post as PR comment
          gh pr comment ${{ github.event.pull_request.number }} \
            --body "$(echo '## ðŸ“Š Schema Diff'; echo '```sql'; cat diff.txt; echo '```')"
        env:
          GH_TOKEN: ${{ github.token }}

  # Job 2: Upload to S3 (runs on merge to main)
  deploy-schema:
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    permissions:
      contents: read

    steps:
      - uses: actions/checkout@v4

      - name: Generate version and upload
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        run: |
          VERSION=$(date -u +%Y%m%d%H%M%S)
          aws s3 cp schema.sql "s3://${{ secrets.S3_BUCKET }}/schemas/$VERSION/schema.sql"
          echo "ðŸš€ Deployed schema version $VERSION"
```

### Lifecycle Hook Examples for Production

**Simple Slack notification (inline):**
```bash
docker run -d \
  -e ON_APPLY_SUCCEEDED='curl -X POST $SLACK_WEBHOOK_URL -H "Content-Type: application/json" -d "{\"text\":\"Schema $DB_SCHEMA_SYNC_VERSION applied\"}"' \
  -e SLACK_WEBHOOK_URL=https://hooks.slack.com/services/YOUR/WEBHOOK/URL \
  ghcr.io/tokuhirom/db-schema-sync:latest watch
```

**Using external script for complex logic:**

If you need complex notification logic, create a script file and mount it:

```bash
# Create notify-slack.sh
cat > notify-slack.sh <<'EOF'
#!/bin/bash
curl -X POST "$SLACK_WEBHOOK_URL" \
  -H 'Content-Type: application/json' \
  -d "{\"text\":\"âœ… Schema $DB_SCHEMA_SYNC_VERSION applied to $DB_NAME\"}"
EOF
chmod +x notify-slack.sh

# Mount and use the script
docker run -d \
  -e ON_APPLY_SUCCEEDED=/scripts/notify-slack.sh \
  -e SLACK_WEBHOOK_URL=https://hooks.slack.com/services/YOUR/WEBHOOK/URL \
  -v ./notify-slack.sh:/scripts/notify-slack.sh:ro \
  ghcr.io/tokuhirom/db-schema-sync:latest watch
```

## Version Formats

The tool supports semantic version comparison. Supported formats:
- Simple versions: `v1`, `v2`, `v10` (v10 > v9)
- Semver: `1.0.0`, `2.0.0`, `1.10.0`
- Semver with v prefix: `v1.0.0`, `v2.0.0`
- Timestamps: `20240101120000`

## Development

### Build

```bash
make build
```

### Test

```bash
# Run unit tests
make test

# Run integration tests (requires Docker)
make test-integration
```

### Lint

```bash
make lint
```
